# üèÄ NCAA Basketball ELT Pipeline (GCP + dbt + Kestra)

This project showcases a modern ELT (Extract, Load, Transform) pipeline processing data from the NCAA Basketball dataset. The goal is to demonstrate that an end-to-end data pipeline is fully deployed on the Google Cloud Platform (GCP), from infrastructure provisioning to analytics and visualization. Each tile in looker helps with visualazing aggregated data about players, player events, teams and historical tournaments.

## ‚öôÔ∏è Technologies Used

- **Google Cloud Platform (GCP)** ‚Äì Hosts the entire infrastructure.
- **Terraform** ‚Äì Automates infrastructure provisioning (VM instance, Cloud SQL, GCS, BigQuery...).
- **Docker Compose** ‚Äì Runs Kestra and PgAdmin on a VM.
- **Kestra** ‚Äì Workflow orchestration (data ingestion and loading to BigQuery).
- **PostgreSQL (Cloud SQL)** ‚Äì Metadata backend for Kestra.
- **Google Cloud Storage (GCS)** ‚Äì Raw file storage.
- **BigQuery** ‚Äì Cloud data warehouse for analytical models.
- **dbt (Data Build Tool)** ‚Äì Transforms raw data into analytical models in BigQuery.
- **Looker** ‚Äì Business intelligence and data visualization layer.

## üîÑ ELT Data Flow

1. **Infrastructure Provisioning**  
   Terraform creates all necessary GCP resources:
   - VM instance (Compute Engine)
   - Cloud SQL (PostgreSQL)
   - GCS bucket for raw data
   - BigQuery datasets

2. **Workflow Orchestration with Kestra**  
   - Kestra runs on a Docker container inside the VM
   - Kestra workflows:
     - Download raw data (e.g., public API or datasets)
     - Store data in GCS
     - Load data from GCS to BigQuery (raw tables)

3. **Data Transformation with dbt**  
   - dbt models transform raw data into intermediate, dimensional, and fact layers
   - Results are materialized in BigQuery

4. **Visualization with Looker**  
   - Transformed data is explored and visualized in Looker dashboards
   - Dashboards highlight player performance, team stats, game events, and trends

## üì¶ Deployment Stack

Infrastructure and services are managed with:
- `Terraform` for provisioning cloud resources
- `Docker Compose` for running Kestra and PgAdmin on the VM

## üìä Architecture Diagram

![Architecture](./img/diagram.png)

## üìÅ Project Structure
‚îú‚îÄ‚îÄ terraform/ # Terraform config for GCP resources 
‚îú‚îÄ‚îÄ kestra/ # Kestra workflows (YAML) 
‚îú‚îÄ‚îÄ dbt/ # dbt project for data modeling 
‚îú‚îÄ‚îÄ docker/ # Deployment of Kestra and PgAdmin 
‚îú‚îÄ‚îÄ README.md # Project overview


## Manual for deployment
First, let's create the SSH key for the Virtual machine  
Generate SSH key: 

https://cloud.google.com/compute/docs/connect/add-ssh-keys
https://cloud.google.com/compute/docs/connect/create-ssh-keys#windows-10-or-later

Windows:
<pre lang="markdown"> ssh-keygen -t rsa -f C:\Users\WINDOWS_USER\.ssh\KEY_FILENAME -C USERNAME</pre>  

Linux:<pre lang="markdown"> ssh-keygen -t rsa -f ~/.ssh/KEY_FILENAME -C USERNAME</pre>   

Create the project on the Google Cloud Console. The Terraform will automatically use Application Default Account (your Gmail to create the Infrastructure).  
It will create one service account with all the necessary permission (not the best practice, but for project will do) after that it will download the key json file  
into the terraform folder, which will be used later.
If the GOOGLE_APPLICATION_CREDENTIALS environment variable is set, it will override ADC. 
Use any of these in terminal:
<pre lang="markdown">Remove-Item Env:GOOGLE_APPLICATION_CREDENTIALS</pre>
<pre lang="markdown">$Env:GOOGLE_APPLICATION_CREDENTIALS</pre>

Establish adc with gcloud auth application-default login
cherck with:

gcloud auth list 

set correctly with:
<pre lang="markdown">gcloud projects add-iam-policy-binding ncaa-project-455618 \
--member="user: YOUR GMAIL HERE" \
--role="roles/serviceusage.serviceUsageConsumer"</pre>

Now that this is set up just add the projects id as the default connected project on gcloud:
<pre lang="markdown">`gcloud auth application-default set-quota-project PROJECT-ID`</pre>

Now all that is needed is simple. It will take some time to set up. PostgreSQL and Dataproc usauslay takes about 4-5min:
<pre lang="markdown">`terraform init`</pre>
<pre lang="markdown">`terraform plan`</pre>
<pre lang="markdown">`terraform apply`</pre>

Logging into the vm with ssh key. You need the external ip from the VM on gcloud when it is running.  
Check for the External IP to connect to the VM machine.  
With a command you can access the VM or create a config file with structure like this
<pre lang="markdown">ssh -i ~/.ssh/gcp_ssh user@externalip</pre> 

<pre lang="markdown">Host vm-instance-1
    HostName externalIP
    User user
    IdentityFile c:/Users/user/.ssh/gpc_ssh</pre>



