{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import math\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get google credentials downloaded by terraform\n",
    "file_path = \"../terraform/gcp_credentials.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your project name here \n",
    "client = bigquery.Client(credentials=credentials, project=\"dte-de-course-454810\")\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be - bigquery-public-data, ncaa_basketball\n",
    "project_id = \"bigquery-public-data\"\n",
    "dataset_id = \"ncaa_basketball\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = client.dataset(dataset_id, project=project_id)\n",
    "tables = list(client.list_tables(dataset_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be - ncaa-bucket-dump\n",
    "bucket_name = \"kestra-storage-1997\"\n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for table in tables:\n",
    "\n",
    "table_name = tables[1].table_id\n",
    "\n",
    "query_job = client.query(f\"\"\"\n",
    "                             SELECT *\n",
    "                             FROM `{project_id}.{dataset_id}.{table_name}`\n",
    "                             \"\"\")\n",
    "df = query_job.to_dataframe()\n",
    "\n",
    "chunk_size = 10000  \n",
    "num_chunks = math.ceil(len(df) / chunk_size)\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    df_chunk = df.iloc[i*chunk_size:(i+1)*chunk_size]\n",
    "\n",
    "    csv_buffer = io.BytesIO()\n",
    "\n",
    "    # Write to Buffer\n",
    "    compression_opts = dict(method=\"zip\", archive_name=f\"{table_name}_part_{i+1}.csv\")\n",
    "    df_chunk.to_csv(csv_buffer, index=True, compression=compression_opts)\n",
    "\n",
    "    # Go to the start of thebuffer and load to bucket\n",
    "    csv_buffer.seek(0)  \n",
    "    blob = bucket.blob(f\"{table_name}/{table_name}_part_{i+1}.zip\")\n",
    "    blob.upload_from_file(csv_buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
